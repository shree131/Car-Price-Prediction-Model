{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Used Car Prices with Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project explores the use of Linear Regression to predict the prices of second-hand cars based on key features such as mileage, year, and engine volume. \n",
    "\n",
    "The dataset represents listings from an online platform where individual sellers post their car details. Each row corresponds to a unique vehicle being offered for resale.\n",
    "\n",
    "We'll walk through a full machine learning workflow:\n",
    "- Preprocessing the data\n",
    "- Selecting relevant features and target variables\n",
    "- Checking assumptions for linear regression and handling violations\n",
    "- Scaling the data\n",
    "- Splitting into training and test sets\n",
    "- Building and evaluating a linear regression model\n",
    "\n",
    "The final model will help estimate car prices based on input specifications and provide insights into what features drive value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "# Define custom color palettes\n",
    "cool_tones = ['#347C8D', '#5B7F9A', '#7887AB', '#5D6D7E']\n",
    "warm_tones = ['#B35C4A', '#CB6843', '#E18257', '#D1604D', '#CB6843', '#E3A370', '#A0432F']\n",
    "\n",
    "# Set color palette\n",
    "sns.set_palette(cool_tones)\n",
    "\n",
    "# Set the style and format the spine\n",
    "sns.set_style(\"white\", {\"axes.spines.right\": False, \"axes.spines.top\": False, \"axes.spines.left\": True, \"axes.spines.bottom\": True})\n",
    "plt.rcParams['axes.edgecolor'] = '#444444'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Loading the Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../data/second_hand_car_data.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print column info \n",
    "print(raw_data.info())\n",
    "\n",
    "# Generate desciptive statistics for all fields\n",
    "raw_data.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Observations**\n",
    "\n",
    "- There are **4,345** total rows in the dataset, but some columns like `Price` and `EngineV` have missing values.\n",
    "- The `Model` column contains **312 unique values**, which would require creating an equal number of dummy variables — too many for a linear model.\n",
    "- Fortunately, the `Model` information largely overlaps with other features like `Brand`, `Year`, and `EngineV`, so we can safely drop it.\n",
    "- The `Registration` column is overwhelmingly filled with **\"Yes\"** values (3,947 of 4,345), so it doesn't offer any useful variability for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Variables of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed, we’ll begin by dropping the `Model` and `Registration` columns since they don’t add useful information for price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column 'Model' and 'Registration'\n",
    "data = raw_data.drop(columns = ['Model', 'Registration'], axis = 1)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to second-hand cars, price is heavily influenced by a few key specifications:\n",
    "\n",
    "- **Brand**: Luxury and premium brands tend to have higher resale values.\n",
    "- **Mileage**: Higher mileage usually lowers the value, signaling more wear and tear.\n",
    "- **Engine Volume (EngineV)**: Sports and performance vehicles typically have larger engines.\n",
    "- **Year**: Newer cars generally cost more — with some exceptions like vintage collectibles.\n",
    "\n",
    "Other categorical features will be reviewed individually and encoded appropriately if useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "Earlier, we observed that the dataset contains missing values in the `Price` and `EngineV` columns. These features are crucial to our analysis — `Price` is our target variable, and `EngineV` is one of the key predictors.\n",
    "\n",
    "Let's take a closer look at the number of missing values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the number of missing values in each column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that missing values occur only in a small fraction of the dataset (less than **1%** of observations), and that these values belong to essential features, we will drop those rows. This approach allows us to maintain data quality without sacrificing too much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "data_no_null = data.dropna(axis = 0)\n",
    "data_no_null.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Distributions of Key Features\n",
    "\n",
    "Before we begin modeling, it’s important to understand how our main variables are distributed. This helps us spot potential skewness, outliers, and non-linear relationships — all of which influence how we prepare our data and choose modeling techniques.\n",
    "\n",
    "We'll visualize the probability density functions **(PDFs)** of four key numerical features: `Price`, `Mileage`, `EngineV`, and `Year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PDFs of key continuous variables\n",
    "fig, axes = plt.subplots(2, 2, figsize = (10, 5))\n",
    "columns_pdf = ['Price', 'Mileage', 'EngineV', 'Year']\n",
    "title_format = {'fontweight': 'bold', 'fontsize': 12}\n",
    "title_format_large = {'fontweight': 'bold', 'fontsize': 14}\n",
    "\n",
    "for idx, col in enumerate(columns_pdf):\n",
    "    i = idx // 2  # row index\n",
    "    j = idx % 2   # column index\n",
    "    sns.histplot(data_no_null[col], kde = True, ax = axes[i, j], color = cool_tones[0])\n",
    "    axes[i, j].set_title(col, fontdict = title_format)\n",
    "    axes[i, j].set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization gives us a sense of the underlying shape of each variable:\n",
    "\n",
    "- Are there outliers skewing the distribution?\n",
    "- Is the data normally distributed or skewed?\n",
    "- Should we consider transformations (like log-scaling) to normalize variables such as Price?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Outliers\n",
    "Outliers are data points that significantly deviate from the rest of the dataset. These can distort statistical analyses and models — especially linear regression, which is sensitive to extreme values.\n",
    "\n",
    "Let’s address outliers in four key features: `Price`, `Mileage`, `EngineV`, and `Year`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_null['Price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Observation:**\n",
    "\n",
    "- Mean price is around $19,552.\n",
    "\n",
    "- 75% of cars are priced under $21,900.\n",
    "\n",
    "- However, the maximum price is $300,000 — far higher than the rest. This highly **right-skewed** distribution suggests the presence of extreme values.\n",
    "\n",
    "We’ll remove the **top 1%** of values using the 99th percentile as a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_cap = data_no_null['Price'].quantile(0.99)\n",
    "data_no_outliers = data_no_null[data_no_null['Price'] < price_cap]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Mileage**\n",
    "\n",
    "Mileage also tends to be **right-skewed**, where a few high-mileage vehicles may not represent the typical range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mileage_cap = data_no_outliers['Mileage'].quantile(0.99)\n",
    "data_no_outliers = data_no_outliers[data_no_outliers['Mileage'] < mileage_cap]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Engine Volume (EngineV)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_null['EngineV'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "- Most engine volumes fall between 1.8L and 3.0L.\n",
    "\n",
    "- A max value of **99.99L** is clearly unrealistic and likely an entry error.\n",
    "\n",
    "We'll cap the acceptable range at **6.5L**, which is a reasonable upper limit for modern consumer vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_outliers = data_no_outliers[data_no_outliers['EngineV'] <= 6.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Year**\n",
    "Most cars in the dataset are relatively new, but a few very old models may skew our analysis.\n",
    "\n",
    "We’ll remove the **bottom 10%** by taking the 10th percentile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_floor = data_no_outliers['Year'].quantile(0.10)\n",
    "data_no_outliers = data_no_outliers[data_no_outliers['Year'] > year_floor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing the Cleaned Dataset\n",
    "\n",
    "After handling outliers, we reset the index and summarize the cleaned dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_no_outliers.reset_index(drop = True)\n",
    "data_cleaned.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "We've now removed approximately **250 outlier observations**, improving the quality of our dataset and making it more suitable for linear regression. All feature ranges now fall within realistic, interpretable bounds.\n",
    "\n",
    "We'll compare how the distributions of key numerical features have changed after removing outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to compare\n",
    "features = ['Price', 'Mileage', 'EngineV', 'Year']\n",
    "\n",
    "# Set up the subplot grid\n",
    "fig, axes = plt.subplots(len(features), 2, figsize = (12, 10))\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    # Before outlier removal\n",
    "    sns.histplot(data_no_null[feature], kde = True, ax = axes[i, 0])\n",
    "    axes[i, 0].set_title(f'{feature} (Before)', fontdict = title_format)\n",
    "    axes[i, 0].set_xlabel('')\n",
    "\n",
    "    # After outlier removal\n",
    "    sns.histplot(data_cleaned[feature], kde = True, ax = axes[i, 1], color = warm_tones[3])\n",
    "    axes[i, 1].set_title(f'{feature} (After)', fontdict = title_format)\n",
    "    axes[i, 1].set_xlabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step: 4 Checking the OLS assumptions\n",
    "\n",
    "Before we jump into modeling, it's important to assess whether our data meets the key assumptions of **Ordinary Least Squares (OLS)** regression. We’ve already cleaned and preprocessed our data — next, we'll check for **linearity**, a foundational assumption for linear regression.\n",
    "\n",
    "We're especially interested in the relationships between `Price` and the continuous numerical variables: `Year`, `EngineV`, and `Mileage`. Categorical variables like `Brand`, `Body`, and `Engine Type` will be handled separately using dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Linearity\n",
    "Let’s use scatter plots to examine the relationship between the **target** (Price) and these potential **predictors**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots to examine linearity\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey = True, figsize = (15, 3))\n",
    "\n",
    "year_range = np.arange(data_cleaned['Year'].min(), data_cleaned['Year'].max(), 2)\n",
    "ax1.scatter(data_cleaned['Year'], data_cleaned['Price'], alpha = 0.3, color = cool_tones[0])\n",
    "ax1.set_title('Price vs Year', fontdict = title_format_large)\n",
    "ax1.set_xticks(year_range)\n",
    "\n",
    "ax2.scatter(data_cleaned['EngineV'], data_cleaned['Price'], alpha = 0.3, color = cool_tones[1])\n",
    "ax2.set_title('Price vs Engine Volume', fontdict = title_format_large)\n",
    "\n",
    "ax3.scatter(data_cleaned['Mileage'], data_cleaned['Price'], alpha = 0.3, color = cool_tones[2])\n",
    "ax3.set_title('Price vs Mileage', fontdict = title_format_large)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "There are visible relationships, but they aren’t strictly linear.\n",
    "\n",
    "In particular, `Price` appears to be **right-skewed**, suggesting an exponential distribution.\n",
    "\n",
    "\n",
    "This violates the linearity assumption. Fortunately, there’s a simple fix: **log-transforming** the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relaxing Linearity with a Log Transformation\n",
    "Taking the log of `Price` can help us linearize the relationships and stabilize variance (addressing **heteroskedasticity** as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform the Price\n",
    "data_cleaned['Log Price'] = np.log(data_cleaned['Price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let’s visualize the relationships again — this time using Log Price instead of Price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots after log transformation\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey = True, figsize = (15, 3))\n",
    "\n",
    "ax1.scatter(data_cleaned['Year'], data_cleaned['Log Price'], alpha = 0.3, color = warm_tones[4])\n",
    "ax1.set_title('Log Price vs Year', fontdict = title_format_large)\n",
    "\n",
    "ax2.scatter(data_cleaned['EngineV'], data_cleaned['Log Price'], alpha = 0.2, color = warm_tones[2])\n",
    "ax2.set_title('Log Price vs Engine Volume', fontdict = title_format_large)\n",
    "\n",
    "ax3.scatter(data_cleaned['Mileage'], data_cleaned['Log Price'], alpha = 0.3, color = warm_tones[5])\n",
    "ax3.set_title('Log Price vs Mileage', fontdict = title_format_large)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are much better! The relationships now appear more linear and suitable for regression.\n",
    "\n",
    "Since we’ll be using Log Price as the new target variable, let’s remove the original Price column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original Price column\n",
    "data_cleaned.drop(columns=['Price'], inplace=True)\n",
    "data_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of OLS Assumptions:**\n",
    "\n",
    "| **Assumption**                | **Explanation**                                                                 | **Action Taken** / **Observation**                                                                 |\n",
    "|------------------------------|----------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|\n",
    "| 1. Linearity            | Relationship between predictors and target must be linear.                      | Plotted scatter plots. Observed non-linear patterns. Applied **log transformation** to `Price`.     |\n",
    "| 2. Normality of Errors   | Residuals should be normally distributed.                                       | Applied **log transformation** to improve normality. Supported further by **Central Limit Theorem**.|\n",
    "| 3. Homoscedasticity      | Constant variance of errors across predictors.                                  | Log transformation also helps mitigate **heteroskedasticity** (non-constant variance).              |\n",
    "| 4. No Autocorrelation    | Errors should not be correlated across observations.                            | Not a concern — data is cross-sectional, not time-based.                                            |\n",
    "| 5. No Multicollinearity  | Predictors should not be highly correlated.                                     | Will be checked during feature selection (e.g., using **VIF**).                                     |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity\n",
    "Multicollinearity occurs when two or more predictor variables are highly correlated with each other. This can distort the estimation of coefficients in a regression model and reduce interpretability.\n",
    "\n",
    "In our case, it's logical to suspect that `Year` and `Mileage` might be correlated — newer cars typically have lower mileage. To detect and quantify multicollinearity, we use **Variance Inflation Factor (VIF)** from the `statsmodels` library.\n",
    "\n",
    "- *VIF = 1 - No correlation.*\n",
    "- *VIF between 1 and 5 - Acceptable.*\n",
    "- *VIF > 5 - Potential multicollinearity concern.*\n",
    "- *VIF > 10 - Serious multicollinearity.*\n",
    "\n",
    "Full documentation: [statsmodels.org - VIF](https://www.statsmodels.org/dev/_modules/statsmodels/stats/outliers_influence.html#variance_inflation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all columns in the cleaned dataset\n",
    "data_cleaned.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the VIF function\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Define a subset of continuous variables to check for multicollinearity\n",
    "variables = data_cleaned[['Mileage', 'Year', 'EngineV']]\n",
    "\n",
    "# Create a DataFrame to store VIF values\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF\"] = [variance_inflation_factor(variables.values, i) for i in range(variables.shape[1])]\n",
    "vif.index = variables.columns\n",
    "\n",
    "# Display the VIF table\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation & Action:**\n",
    "\n",
    "If we look at the VIF table, we'll likely observe that the `Year` variable has a high VIF, confirming our hypothesis. Since multicollinearity can distort our regression estimates, we choose to **remove** `Year` from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Year' to reduce multicollinearity\n",
    "data_no_multicollinearity = data_cleaned.drop(['Year'], axis = 1)\n",
    "\n",
    "# Check the remaining features\n",
    "data_no_multicollinearity.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dummy Variables\n",
    "To handle categorical variables for regression, we convert them into dummy variables using `pandas.get_dummies()`. This function creates new binary columns (0 or 1) for each category in a feature.\n",
    "\n",
    "*Note: If a categorical variable has **N categories**, we only need **N - 1 dummy variables**. One category is omitted and acts as the reference level (baseline), avoiding multicollinearity. For example, if we drop `Brand_Audi`, it becomes the benchmark, and all other brand dummies values are in comparision to this baseline value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dummy variables, dropping the first to avoid multicollinearity\n",
    "data_with_dummies = pd.get_dummies(data_no_multicollinearity, drop_first = True)\n",
    "\n",
    "# Check current column names\n",
    "data_with_dummies.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For consistency and interpretability, we’ll rearrange the columns, putting the dependent variable Log Price first, followed by numerical and dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rearranged column order\n",
    "cols = ['Log Price', 'Mileage', 'EngineV', 'Brand_BMW',\n",
    "        'Brand_Mercedes-Benz', 'Brand_Mitsubishi', 'Brand_Renault',\n",
    "        'Brand_Toyota', 'Brand_Volkswagen', 'Body_hatch', 'Body_other',\n",
    "        'Body_sedan', 'Body_vagon', 'Body_van', 'Engine Type_Gas',\n",
    "        'Engine Type_Other', 'Engine Type_Petrol']\n",
    "\n",
    "# Create a new dataframe with reordered columns\n",
    "data_preprocessed = data_with_dummies[cols]\n",
    "\n",
    "# Preview the final preprocessed data\n",
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we are done with the preprocessing step. Next, we're ready for building the **Linear Regression model**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Inputs and Targets\n",
    "We’ll now define our **dependent variable** (`Log Price`) and **independent variables** (all other features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target (dependent variable)\n",
    "targets = data_preprocessed['Log Price']\n",
    "\n",
    "# Define the input features by dropping the target column\n",
    "inputs = data_preprocessed.drop(columns = ['Log Price'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data\n",
    "\n",
    "We standardize the **input features** to ensure they’re on the same scale. This prevents features with larger values from disproportionately influencing the model.\n",
    "\n",
    "*Note: While scaling dummy variables isn’t recommended in classical stats models (since 0/1 represents categories), in machine learning, it doesn’t affect predictive power. However, they do lose their interpretive \"dummy\" nature when scaled.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create and fit the scaler on the input features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(inputs)\n",
    "\n",
    "# Transform the inputs using the fitted scaler\n",
    "inputs_scaled = scaler.transform(inputs)\n",
    "\n",
    "# View the scaled inputs\n",
    "inputs_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our features are now standardized and ready for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Training and Testing Dataset\n",
    "\n",
    "Now that our features are standardized, it's time to split the data into **training** and **testing** sets. This helps us prevent **overfitting** and evaluate how well the model performs on unseen data. We’ll use an **80-20 split**, where:\n",
    "\n",
    "- 80% of the data is used to train the model.\n",
    "- 20% is held back for testing.\n",
    "- We set a random_state to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module for splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data: 80% training, 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs_scaled, targets, test_size = 0.2, random_state = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Fit the Regression Model:**\n",
    "\n",
    "We’ll start by training a log-linear regression model using the scaled training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Predictions vs Actuals:**\n",
    "\n",
    "Let’s compare the model’s predictions to the actual target values using a scatter plot. We will also analyze the **residuals** (the difference between the actual and predicted values) to check the assumptions of linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the training data\n",
    "y_hat = reg.predict(x_train)\n",
    "\n",
    "# Calculate residuals\n",
    "residual = y_train - y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (9, 3))\n",
    "\n",
    "# Visualize a scatterplot between predicted vs actual values\n",
    "sns.scatterplot(x = y_train, y = y_hat, alpha = 0.5, ax = ax1, color = cool_tones[0])\n",
    "ax1.set_xlabel('Actual Values (y_train)')\n",
    "ax1.set_ylabel('Predicted Values (y_hat)')\n",
    "ax1.set_title('Predicted vs Actual (Training Set)', fontdict = title_format)\n",
    "ax1.set_xlim(6, 13)\n",
    "ax1.set_ylim(6, 13)\n",
    "ax1.plot([6, 13], [6, 13], color = warm_tones[1], linestyle = '--')  # 45° reference line\n",
    "\n",
    "# Residual distribution\n",
    "sns.histplot(residual, kde = True, ax = ax2, color = cool_tones[0])\n",
    "ax2.lines[0].set_color(warm_tones[1])\n",
    "ax2.set_title('Residual Distribution', fontdict = title_format)\n",
    "ax2.set_xlabel('Residuals')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "- If the model were perfect, all points would lie exactly on the red **45° line**. In our case, predictions generally cluster around the line, which suggests a reasonably good fit and definitely better than random guessing.\n",
    "\n",
    "- **Residuals** appear roughly normally distributed with a mean near 0. **Slight left skew** suggests that the model sometimes **overestimates** the target values more than it underestimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. R-squared Score:**\n",
    "\n",
    "Let’s check how well our model explains the variance in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** ~0.67\n",
    "\n",
    "This is a decent result — our model explains about **67% of the variability** in the target variable. While not perfect, it shows a solid foundation and can likely be improved in iterative versions through further feature engineering or model tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intercept (bias)\n",
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summary table\n",
    "reg_summary = pd.DataFrame(inputs.columns.values, columns=['Features'])\n",
    "reg_summary['Weights'] = reg.coef_\n",
    "reg_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**1. Interpreting Numerical Variables:**\n",
    "\n",
    "While the model isn’t directly interpretable (due to the log transformation of price and standardization of features), we can still make sense of the results:\n",
    "\n",
    "- **Positive coefficients** mean that an increase in the feature is associated with a higher log price (and thus, a higher actual price). `EngineV` has a positive coefficient. Therefore, larger engine volumes tend to increase a car’s price.\n",
    "\n",
    "- **Negative coefficients** indicate that an increase in the feature tends to lower the price. `Mileage` has a strong negative coefficient. Therefore, more mileage generally reduces the car’s value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Interpreting Dummies:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Brand`\n",
    "\n",
    "- **Audi** was the dropped category, making it the **baseline.**\n",
    "\n",
    "- Brands with **Positive weights** (BMW and Mercedes-Benz) are **more expensive** than Audi.\n",
    "\n",
    "- **Negative weights** (the rest of the brands) are **cheaper** than Audi.\n",
    "\n",
    "`Engine Type`\n",
    "\n",
    "- **Diesel** is the **benchmark** here.\n",
    "\n",
    "- All other engine types have **negative coefficients**, meaning they are **cheaper** than Diesel on average:\n",
    "\n",
    "- **Petrol** has the strongest negative impact. It's the **cheapest** relative to Diesel.\n",
    "\n",
    "We'll create two data Frames to store the weights for `Brand` and `Engine Type` for deriving the final insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frames to store weights for Brand and Engine Type\n",
    "features = reg_summary.copy()\n",
    "brands_bool = features['Features'].astype(str).str.startswith('Brand')\n",
    "eng_bool = features['Features'].astype(str).str.startswith('Engine Type')\n",
    "\n",
    "brands_df = features[brands_bool].copy()\n",
    "engine_df = features[eng_bool].copy()\n",
    "\n",
    "# Clean up 'Features' column to keep only the brand and engine type names\n",
    "brands_df['Features'] = brands_df['Features'].astype(str).str.split('_').str[1]\n",
    "engine_df['Features'] = engine_df['Features'].astype(str).str.split('_').str[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model Testing and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions on Test Data\n",
    "Since our model is trained and fine-tuned, we can move to testing it on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the relationship between the actual test targets and the predicted values using a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot with the test targets and the test predictions\n",
    "\n",
    "plt.figure(figsize = (6, 4))\n",
    "sns.scatterplot(x = y_test, y = y_hat_test, alpha = 0.6, color = warm_tones[4])\n",
    "plt.plot([6, 13], [6, 13], color = cool_tones[3], linestyle = '--')  # 45° reference line\n",
    "\n",
    "plt.xlabel('Targets (y_test)', size = 14)\n",
    "plt.ylabel('Predictions (y_hat)', size = 14)\n",
    "plt.title('Predicted vs Actual (Testing Set)', fontweight = 'bold')\n",
    "plt.xlim(6, 13)\n",
    "plt.ylim(6, 13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "At first glance, the plot looks fairly promising. \n",
    "- We notice a **strong alignment** around the 45° line, especially for **higher-priced** vehicles, indicating **strong predictive performance** in that range.\n",
    "\n",
    "- For **lower prices**, predictions are more scattered, showing **weaker accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also noticed mismatches due to old indices being preserved. Let’s reset the index to align predictions and targets properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the original indexing to match predicted and target values below\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Log Prices Back to Original Scale\n",
    "Our model predicted log-prices. We’ll take the exponential to revert them back to actual price values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert log of Price back to the original values by taking its exponential\n",
    "df_pf = pd.DataFrame(np.exp(y_hat_test), columns = ['Predictions'])\n",
    "df_pf['Target'] = np.exp(y_test)\n",
    "\n",
    "# Calculate the residual and the percent diff\n",
    "df_pf['Residual'] = df_pf['Target'] - df_pf['Predictions']\n",
    "df_pf['Diff %'] = abs(df_pf['Residual'] / df_pf['Target'] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s explore the statistical summary of our predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Takeaways:**\n",
    "\n",
    "- The **minimum percent error** is as low as **0.05%**, showing spot-on predictions in some cases.\n",
    "\n",
    "- The **maximum percent error** is relatively large, indicating a few poor predictions.\n",
    "\n",
    "- Overall, percentiles show that most predictions are reasonably close to actual values.\n",
    "\n",
    "We can sort predictions by percentage error to manually inspect the model’s behavior to check for **outliers**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# Sort by difference in % to manually check the model\n",
    "df_pf.sort_values(by = ['Diff %'], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "- The largest errors occur for cars priced **extremely low** (`$3000`, `$4500`, `$2600`, etc.). In each of these outlier cases, the **predicted price is higher** than the actual (the residual is negative).\n",
    "\n",
    "- We also notice that **extremely high-priced** cars are **underestimated** by the model.\n",
    "\n",
    "- This may suggest **missing features**, such as damage status or vehicle condition, which could significantly impact price but weren't included in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Final Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_min = df_pf['Target'].min()\n",
    "target_max = df_pf['Target'].max()\n",
    "\n",
    "# Visualize the model performance in a scatter plot\n",
    "plt.figure(figsize = (7, 5))\n",
    "sns.scatterplot(data = df_pf, x = 'Target', y = 'Predictions', hue = 'Target', palette = 'mako', legend = False)\n",
    "plt.plot([target_min, target_max], [target_min, target_max], color = warm_tones[0], linestyle = '--') # 45 deg line\n",
    "\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Final Model Performance: Predicted vs Actual Price', fontweight = 'bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training and evaluating our linear regression model, we observed the following insights:\n",
    "\n",
    "- **Strong overall performance:** The model performs reliably across most price ranges, particularly for **low to mid-priced** vehicles, showing consistent and accurate predictions.\n",
    "\n",
    "- **Weaker performance for extremely low-priced cars:** Predictions for extremely low-priced vehicles (e.g., under $5,000) are more **scattered and less reliable**. This may be due to **unaccounted factors** or missing variables (e.g., mileage, damage condition, age) that influence pricing in that range.\n",
    "\n",
    "- **Residual patterns reveal bias:** For outliers on the lower end of the price spectrum, residuals tend to be negative, meaning the model overestimates the actual price.\n",
    "\n",
    "- **Underestimation of luxury cars:** The model tends to **underestimate extremely high-priced vehicles** (above $60,000). These appear to be outliers with limited representation in the dataset, which reduces the model’s ability to learn their pricing patterns effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "# Visualize 'Brand' weights in a bar plot\n",
    "sns.barplot(data = brands_df, y = 'Features', x = 'Weights', hue = 'Features', palette = 'ch:s=.25,rot=-.25', ax = ax1)\n",
    "ax1.set_title('Effect of Car Brand on Price (vs Audi)', fontdict = {'fontweight': 'bold'})\n",
    "ax1.set_xlabel('Weight')\n",
    "# ax1.tick_params(axis='y', labelsize=14)\n",
    "ax1.set_ylabel('')\n",
    "\n",
    "# Visualize 'Engine Type' weights in a bar plot\n",
    "sns.barplot(data = engine_df, y = 'Features', x = 'Weights', hue = 'Features', palette = 'flare', ax = ax2)\n",
    "ax2.set_title('Effect of Car Brand on Price (vs Diesel)', fontdict = {'fontweight': 'bold'})\n",
    "ax2.set_xlabel('Weight')\n",
    "# ax2.tick_params(axis='y', labelsize=14)\n",
    "ax2.set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project demonstrates that the linear regression model we built can provide valuable insights into car pricing. While it's not perfect — especially for extreme outliers — it performs well across most of the price range and helps us interpret the impact of different features like **mileage, engine volume, brand**, and **engine type**.\n",
    "\n",
    "According to the model’s learned weights, **Renault** and **Mitsubishi** tend to drive prices lower, while **BMW** and **Mercedes-Benz** contribute to higher predicted prices, in comparision to **Audi**. In terms of engine type, **Petrol** vehicles are estimated to be significantly cheaper than **Diesel**, with **Gas** and **Other** engine types also pulling prices lower.\n",
    "\n",
    "For further improvement:\n",
    "\n",
    "- Include more features like car model, damage history, and year.  \n",
    "- Handle outliers more effectively or transform features differently.  \n",
    "- Consider using non-linear models or ensemble techniques.  \n",
    "\n",
    "Overall, this was a strong first iteration, and the results show the power of interpretable, data-driven models in predicting real-world values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
